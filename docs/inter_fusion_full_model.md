# Core Perception Features Comprehensive Table

**Important Note**: Each final output (Visual Weight Heatmap, Eye Flow Path, etc.) is produced by either classical OR neural inter-fusion (selected via configuration), not a combination of both. The current design uses a factory/selector pattern to choose one strategy. Combining both outputs could be a future enhancement.

| Feature | What It Shows | User Value | Example | Types/Principles | AI Techniques | Classical CV | Skill Level | Learning Value | Appeal | Implementation | Success Metrics | Hours |
|---------|---------------|------------|---------|-----------------|---------------|--------------|-------------|----------------|--------|----------------|----------------|-------|
| **Visual Weight Heatmap** | Which areas naturally draw viewer's attention | "Where should I look first? What's the focal point?" | Bright red object in gray scene = high visual weight | N/A | • CLIP + Custom Fusion<br>• Custom ViT Attention<br>• Custom CNN | • Color, contrast, edge density<br>• Mathematical formulas | **HIGH** | High - modern AI techniques, semantic understanding | Foundation model experience, multi-modal AI skills | Zero-shot CLIP integration, semantic-visual fusion, custom attention mechanisms; Multi-head attention, positional encoding, custom attention fusion | • Accurately identifies focal points in test images<br>• Correlates with human attention in eye-tracking studies<br>• Provides actionable feedback for composition improvement | 35-50 |
| **Eye Flow Path Overlay** | Natural sequence of eye movements when viewing image | "How will someone's gaze travel through my image?" | Starting at bright object → following leading lines → ending at subject's face | N/A | • Custom LSTM/GRU Sequence Modeling<br>• Transformer Sequence Modeling<br>• Reinforcement Learning | • Gradient-based flow<br>• Monte Carlo sampling | **HIGH** | Maximum - fundamental AI concepts, custom implementation | Shows ability to design and train neural networks, research-grade work | Build LSTM/GRU layers from scratch, design loss functions, train on eye-tracking data; Custom attention layers, positional encoding, multi-head attention for eye movements | • Predicts human eye movement patterns<br>• Shows logical progression through image elements<br>• Helps identify flow bottlenecks or dead ends | 45-70 |
| **Salience Map (Attention Distribution)** | How attention is distributed across entire image | "Is my image balanced? Are there attention dead zones?" | Shows if attention is clustered in one area or spread evenly | N/A | • Custom Salience Architecture<br>• DeepGaze II (pre-trained)<br>• SalGAN (pre-trained)<br>• ML-Net (pre-trained)<br>• ViT Attention Maps | • Merge multiple attention sources<br>• Normalization, smoothing | **MEDIUM** | Medium - CNN design, attention modeling | Computer vision skills, attention mechanism understanding | Custom salience CNN, attention mechanisms, training pipeline | • Shows balanced vs. unbalanced attention distribution<br>• Identifies attention dead zones<br>• Correlates with overall image effectiveness | 15-45 |
| **Visual Hierarchy Analysis** | Order of importance of different elements | "What's the main subject vs. supporting elements?" | Primary subject (high hierarchy) → secondary elements → background | N/A | • Custom Attention-Based Ranking<br>• Object Detection + Ranking<br>• Semantic Segmentation + Ranking | • Multi-scale analysis<br>• Attention ranking | **HIGH** | High - attention mechanisms, custom architecture | Attention mechanism expertise, custom AI implementation | Multi-head attention for hierarchy, custom ranking algorithms, attention visualization; Custom U-Net design, depth-aware loss functions, training pipeline | • Correctly ranks element importance<br>• Identifies primary vs. secondary subjects<br>• Helps optimize subject placement | 40-50 |
| **Balance Assessment** | Whether image feels balanced or weighted to one side | "Does my composition feel stable or lopsided?" | Symmetrical balance vs. asymmetrical balance with visual weight | N/A | • AI-Based Symmetry Detection<br>• Mathematical Analysis (Classical CV) | • Weight distribution analysis<br>• Symmetry detection<br>• Center of mass calculation | **LOW** | Low - basic CNN, limited complexity | Limited - basic neural network skills | Simple CNN for symmetry classification; Weight distribution algorithms, symmetry detection | • Correctly identifies balanced vs. unbalanced compositions<br>• Provides specific balance improvement suggestions<br>• Works across different composition styles | 10-40 |
| **Rhythm and Pattern Detection** | Repetitive elements and visual rhythms in image | "What patterns guide the eye? Is there visual harmony?" | Repeated shapes, colors, or textures that create visual flow | N/A | • CNN Pattern Recognition<br>• Frequency Analysis (Classical CV) | • Frequency analysis (FFT)<br>• Spatial correlation<br>• Temporal flow | **LOW** | Low - basic CNN, limited complexity | Limited - basic neural network skills | Simple CNN for pattern classification; FFT algorithms, pattern detection | • Detects visual rhythms and patterns<br>• Shows how patterns guide eye movement<br>• Identifies rhythm disruptions | 15-45 |
| **Depth and Layering Analysis** | How image creates sense of depth and layering | "How does my image create depth? What's foreground vs. background?" | Focus areas, depth of field, atmospheric perspective | N/A | • Custom CNN for Monocular Depth Estimation<br>• Semantic Segmentation with Custom Architecture | • Focus analysis<br>• Atmospheric perspective<br>• Overlap detection | **MEDIUM** | Medium - CNN design, computer vision fundamentals | Computer vision skills, neural network design | Custom encoder-decoder architecture, depth loss functions, training pipeline; Custom U-Net design, depth-aware loss functions, training pipeline | • Correctly identifies foreground/background<br>• Shows depth creation techniques<br>• Helps optimize depth of field | 20-50 |
| **Contrast Analysis (Multiple Types)** | Different types of contrast that affect perception | "What makes elements stand out or blend together?" | Value, color, texture, size, shape contrast | • Value Contrast: Light vs. dark areas<br>• Color Contrast: Complementary or contrasting colors<br>• Texture Contrast: Smooth vs. rough areas<br>• Size Contrast: Large vs. small elements<br>• Shape Contrast: Geometric vs. organic forms | • Multi-dimensional Contrast Computation (Classical CV) | • Local vs. global contrast<br>• Threshold detection<br>• Contrast boundaries | **LOW** | Low - classical CV, no AI/ML | Limited - basic image processing | Contrast computation algorithms, threshold detection | • Identifies all types of contrast present<br>• Shows which contrasts are most effective<br>• Suggests contrast improvements | 10-20 |
| **Gestalt Principles Analysis** | How brain groups and organizes visual elements | "How do viewers naturally group elements in my image?" | Proximity, similarity, continuity, closure, figure/ground | • Proximity: Elements close together are grouped<br>• Similarity: Similar elements are grouped<br>• Continuity: Lines and curves guide the eye<br>• Closure: Brain fills in missing parts<br>• Figure/Ground: What's subject vs. background | • Semantic Grouping with Pre-trained Models<br>• Clustering Algorithms (Classical CV) | • Clustering algorithms<br>• Edge detection<br>• Shape analysis | **LOW** | Low - model integration, limited custom work | Limited - basic model integration skills | Pre-trained model loading, basic post-processing; K-means, hierarchical clustering | • Identifies how elements are grouped<br>• Shows psychological organization<br>• Helps optimize element relationships | 15-40 |
| **Emotional Response Prediction** | What emotional response image is likely to evoke | "What mood or feeling does my image convey?" | Warm colors = comfort, high contrast = drama, soft focus = dreamy | N/A | • Custom CNN + Transfer Learning<br>• Multi-Modal Emotion Recognition | • Color psychology<br>• Composition psychology<br>• Semantic analysis | **MEDIUM** | Medium - transfer learning, classification techniques | Transfer learning skills, custom classification models | Custom emotion CNN, transfer learning pipeline, emotion datasets; Visual-semantic fusion, emotion classification, custom loss functions | • Predicts emotional impact accurately<br>• Identifies mood-conveying elements<br>• Suggests emotional adjustments | 35-45 |

## **Quick Reference**

### **HIGH SKILL DEMONSTRATION (Best for CV/AI)**
1. **Eye Flow Path** - Custom LSTM/GRU (45-70h) - Maximum learning, research-grade
2. **Visual Weight Heatmap** - CLIP + Custom Fusion (35-50h) - Modern AI, multi-modal
3. **Visual Hierarchy** - Custom Attention-Based Ranking (40-50h) - Attention mechanisms

### **MEDIUM SKILL DEMONSTRATION**
4. **Depth and Layering** - Custom CNN for Depth (20-50h) - CNN design, computer vision
5. **Emotional Response** - Custom CNN + Transfer Learning (35-45h) - Transfer learning
6. **Salience Map** - Custom Salience Architecture (15-45h) - CNN design, attention

### **LOW SKILL DEMONSTRATION (Avoid for CV/AI)**
7. **Balance Assessment** - AI-Based Symmetry (10-40h) - Basic CNN, limited complexity
8. **Rhythm and Pattern** - CNN Pattern Recognition (15-45h) - Basic CNN, limited complexity
9. **Contrast Analysis** - Multi-dimensional Contrast (10-20h) - Classical CV, no AI/ML
10. **Gestalt Principles** - Semantic Grouping (15-40h) - Model integration, limited custom work 